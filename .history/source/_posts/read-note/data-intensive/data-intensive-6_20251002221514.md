---
title: 数据密集型应用系统设计-第六章-数据分区
date: 2025-09-28 20:39:32
categories:
   - [Read-Note, 数据密集型应用系统设计]
---

对于⼀个应⽤系统，如果“数据”是其成败决定性因素，包括数据的规模、数据的复杂度或者数据产⽣与变化的速率等，我们就可以称为“数据密集型应⽤系统”，与之对应的是计算密集型（Compute-Intensive），CPU 主频往往是后者最⼤的制约瓶颈

# 分布式系统

## 六、数据分区

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/diagram-1.png)

分区：每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区

目的：提高可扩展性，大数据集分散在更多的磁盘上，查询负载分布，每个节点可以独立执行查询

**数据分区与数据复制**

分区通常与复制结合使用，即每个分区在多个节点都存有副本。这意味着某条记录属于特定的分区，而同样的内容会保存在不同的节点上以提高系统的容错性。

一个节点上可能存储了多个分区。图 6-1 展示了主从复制模型与分区组合使用时数据的分布情况。由图可知，每个分区都有自己的主副本，例如被分配给某节点，而从副本则分配在其他一些节点。一个节点可能即是某些分区的主副本，同时又是其他分区的从副本。

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-26.png)

### 键-值数据的分区

**基于关键字区间分区**

为每个分区分配一段连续的关键字或者关键字区间范围

每个分区内可以按照关键字排序保存，支持区间查询

**基于关键字哈希值分区**

避免数据倾斜，定义哈希函数

对于热点数据在关键字开头添加随机数，如 2 位随机数可以将写操作分布到 100 个关键字上，但读取也需要从所有 100 个关键字读取数据然后合并

### 分区与二级索引

二级索引不能唯一标识一条记录，只是用来加速特定值查询，挑战在于不能规整的映射到分区中

**基于文档分区的二级索引**

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-20.png)

每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据

每当需要写数据库时，包括添加、删除或更新文档等，只需要处理包含目标文档 ID 的那一个分区

读取需要发送到所有分区，尽量单个分区满足二级索引

**基于词条的二级索引分区**

对所有的数据构建全局索引，而不是每个分区维护自己的本地索引，但索引也需要分区

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-27.png)

以待查找的关键字本身作为索引，可以通过关键词排序换分索引分区（如 a-r 在分区 0，s-z 在分区 1），也可以哈希划分

读取只用向包含词条的那一个分区发出读请求，写入会变慢，如果有多个二级索引并且分布在多个分区，导致写多个分区

一般不支持同步更新全局二级索引，采用异步更新

### 分区再平衡

* 查询压力增加，因此需要更多的 CPU 来处理负载。

* 数据规模增加，因此需要更多的磁盘和内存来存储数据。

* 节点可能出现故障，因此需要其他机器来接管失效的节点。

要求数据和请求可以从一个节点转移到另一个节点，这样一个迁移负载的过程称为再平衡

无论对于哪种分区方案，分区再平衡通常至少要满足：

* 平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布。

* 再平衡执行过程中，数据库应该可以继续正常提供读写服务。

* 避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘 I/O 影响

**动态再平衡的策略**

为什么不取模？如果节点数变化，导致很多关键字节点迁移

**固定数量分区**

创建远超实际节点数的分区数，然后为每个节点分配多个分区

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-15.png)

分区的数量往往在数据库创建时就确定好，之后不会改变。原则上也可以拆分和合并分区（稍后介绍），但固定数量的分区使得相关操作非常简单，因此许多采用固定分区策略的数据库决定不支持分区拆分功能。所以，在初始化时，已经充分考虑将来扩容增长的需求（未来可能拥有的最大节点数），设置一个足够大的分区数。而每个分区也有些额外的管理开销，分区数量过多可能会有副作用

如果数据集的总规模高度不确定或可变，此时如何选择合适的分区数就有些困难。每个分区包含的数据量的上限是固定的，实际大小应该与集群中的数据总量成正比。如果分区里的数据量非常大，则每次再平衡和节点故障恢复的代价就很大；但是如果一个分区太小，分区数量就会太多，产生太多的开销。分区大小应该“恰到好处”，不要太大，也不能过小，如果分区数量固定了但总数据量却高度不确定，就难以达到一个最佳取舍点。

**动态分区**

分区大小超过阈值，拆分为两个分区，分区缩小到某个阈值以下，与相邻分区合并

与固定数量的分区一样，每个分区总是分配给一个节点，而每个节点可以承载多个分区。

当一个大的分区发生分裂之后，可以将其中的一半转移到其他某节点以平衡负载

**按节点比例分区**

分区数与集群节点数成正比关系，每个节点具有固定数量的分区

当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系；当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大量的节点来存储，因此这种方法也使每个分区大小保持稳定

新增节点，随机选择固定数量的现有分区进行分裂，然后拿走这些分区的一半数据量，将另一半数据留在原节点，要求采用基于哈希分区

### 请求路由

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-35.png)

也可以依靠独立的协调服务（如 ZooKeeper）跟踪集群范围内的元数据

![](https://cdn.jsdelivr.net/gh/1935Zz/1935zz.github.io/source/img/data-intensive/image-30.png)

**并行查询执行**

对于大规模并行处理（massivelyparallelprocessing，MPP）这一类主要用于数据分析的关系数据库，在查询类型方面要复杂得多。典型的数据仓库查询包含多个联合、过滤、分组和聚合操作。MPP 查询优化器会将复杂的查询分解成许多执行阶段和分区，以便在集群的不同节点上并行执行。尤其是涉及全表扫描这样的查询操作，可以通过并行执行获益颇多。






